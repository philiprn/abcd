{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99512c7b-3f22-4947-b5a3-d1574d100a84",
   "metadata": {},
   "source": [
    "# CatBoost models\n",
    "\n",
    "## Data\n",
    "We analyze a synthetic version of the data, created in the R script.\n",
    "The synthetic dataset is a copy of the top 50 most important variables of the phase 4 dataset (age 11-12, $N=2224$, $p=380$ - analysed in the paper), together with a synthetic version of the outcome variable (SDQ score at age 15-16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68dac86d-9445-4024-af96-ab4307b73cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import Pool, CatBoostClassifier, cv, EFstrType\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from numba import NumbaDeprecationWarning\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d69de7-fba1-4e6c-9212-705c620c2cad",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'synthetic-dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msynthetic-dataset.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotaalSDQkind_f5\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      4\u001b[0m y[np\u001b[38;5;241m.\u001b[39mwhere(y \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(y, \u001b[38;5;241m90\u001b[39m))[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/catenv/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/catenv/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/catenv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/catenv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/envs/catenv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/catenv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/envs/catenv/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'synthetic-dataset.csv'"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(\"synthetic-dataset.csv\")\n",
    "\n",
    "y = X['TotaalSDQkind_f5'].values\n",
    "y[np.where(y < np.percentile(y, 90))[0]] = 0\n",
    "y[np.where(y >= np.percentile(y, 90))[0]] = 1\n",
    "\n",
    "X = X.drop(['TotaalSDQkind_f5'], axis=1)\n",
    "\n",
    "# subtract 1 because this is Python\n",
    "categorical_features_indices = np.array([3,4,7,23,27,29,33,39,40,41,46])  - 1\n",
    "\n",
    "categorical_features_indices=categorical_features_indices[1:]\n",
    "\n",
    "# convert categorical feature values to strings\n",
    "q = ['str']*len(categorical_features_indices)\n",
    "foo = dict(zip(X.columns[categorical_features_indices], q))\n",
    "X = X.astype(foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f79fa-daad-4a82-b001-42750af1064d",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a77c8d-ba40-4ed5-b25e-98bb17f8cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.8, random_state=123)\n",
    "\n",
    "train_data = Pool(data = X_train,\n",
    "                  label = y_train,\n",
    "                  cat_features = categorical_features_indices)\n",
    "\n",
    "validation_data = Pool(data = X_validation,\n",
    "                  label = y_validation,\n",
    "                  cat_features = categorical_features_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263ac51b-ac0c-4d38-9dc5-5ec765669083",
   "metadata": {},
   "source": [
    "## Train baseline\n",
    "\n",
    "Before tuning any other parameters, we first tune learning rate and number of iterations manually with a trial run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99638186-b589-433b-a56d-1fe9437e1d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(loss_function='Logloss',\n",
    "                           class_weights=[0.1,0.9],\n",
    "                           random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          cat_features = categorical_features_indices,\n",
    "          eval_set=(X_validation, y_validation),\n",
    "          verbose=500,\n",
    "          plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d31f43d-2e40-4731-baf8-4fdfecf7dfa4",
   "metadata": {},
   "source": [
    "In the logging output we can read the iteration with the best value, the chosen learning rate, and the performance (measured in log-loss) on the evaluation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca7b765-c285-4583-b02c-f3d5e9b22c7d",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "To perform a grid search we use Scikit-learn GridsearchCV functionality. We first define the model with a sufficiently large number of iterations. In the fit() function we set the early_stopping_rounds parameter which ensures each model stops training after the loss function has not improved for a defined number of iterations. This saves a lot of time.\n",
    "Because gridSearchCV by default maximizes the scoring function we use the negative log-loss (as the log-loss must be minimized). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa52a7e-d2c5-4296-9035-e970b814d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=1e3,\n",
    "                           class_weights=[0.1,0.9],\n",
    "                           random_state=0)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'depth': [2, 4, 6]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='neg_log_loss',#'roc_auc',\n",
    "                           cv=5,\n",
    "                           verbose=4)\n",
    "\n",
    "grid_search.fit(X_train, y_train, \n",
    "                cat_features=categorical_features_indices,\n",
    "                eval_set=(X_validation, y_validation),\n",
    "                early_stopping_rounds=50,\n",
    "                verbose=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa2252-3850-408d-a0a3-ee3f5ff73e5c",
   "metadata": {},
   "source": [
    "The best parameter combination can be found with the best_params_ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64839519-0970-48d1-9dca-1a18efbde0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714c86b1-441e-49de-94df-6a232cbc8d00",
   "metadata": {},
   "source": [
    "We can also print an overview of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb796876-8d67-4a92-89cb-e0f7c41323da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_results = pd.DataFrame({'depth': grid_search.cv_results_['param_depth'],\n",
    "                    'acc': grid_search.cv_results_[\"mean_test_score\"]})\n",
    "\n",
    "print(gs_results.sort_values(by=['acc'],ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4fad3b-cf8f-41c1-9b81-359fef96ec8e",
   "metadata": {},
   "source": [
    "## Train final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ee465-ea7b-47bd-8aef-f1a2ada48258",
   "metadata": {},
   "source": [
    "We train the final model with the optimized tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ce0a6-54ee-404b-acf9-e53da6a70694",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(loss_function='Logloss',\n",
    "                           early_stopping_rounds=50,\n",
    "                           depth=grid_search.best_params_['depth'],\n",
    "                           class_weights=[0.1,0.9],\n",
    "                           random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          cat_features = categorical_features_indices,\n",
    "          eval_set=(X_validation, y_validation),\n",
    "          verbose=500,\n",
    "          plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6be868c-1c5d-428e-ab8b-59ec5a311e48",
   "metadata": {},
   "source": [
    "## Evaluate performance\n",
    "\n",
    "We calculate several classification performances, both manually and using scikit-learn functionality where possibile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ded84-a7d1-4a08-b79c-341fccbeae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_validation)\n",
    "\n",
    "probs = model.predict_proba(X_validation)\n",
    "\n",
    "# Error rate / accuracy\n",
    "errors=0\n",
    "for i in range(len(y_validation)):\n",
    "    if preds[i] != y_validation[i]:\n",
    "        errors+=1\n",
    "acc = 1 - errors/len(X_validation)\n",
    "\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] == 1:\n",
    "        if y_validation[i] == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    if preds[i] == 0:\n",
    "        if y_validation[i] == 0:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "performances = pd.DataFrame({'AUC': ['-', roc_auc_score(y_validation, probs[:,1])],\n",
    "                             'Accuracy': [acc, accuracy_score(y_validation,preds)],\n",
    "                             'Sensitivity:': [tp/(tp+fn), recall_score(y_validation,preds)],\n",
    "                             'Specificity:': [tn/(fp+tn), '-'],\n",
    "                             'Precision:': [tp/(tp+fp), precision_score(y_validation,preds)],\n",
    "                             'F-measure:': [2*tp/(2*tp+fp+fn), f1_score(y_validation,preds)],\n",
    "                             'MCC': [((tp*tn)-(fp*fn)) / np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)),\n",
    "                                     matthews_corrcoef(y_validation,preds)]}, index=['Manually', 'scikit-learn'])\n",
    "\n",
    "performances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce101455-e645-407f-b2e3-326e227881ee",
   "metadata": {},
   "source": [
    "## ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a66666-ecc5-4a08-ba0d-64d90a951a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_validation, probs[:,1], pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a264383-f818-48a8-b33f-afdca3342255",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))#(8,6))\n",
    "plt.plot([0,1],[0,1],\"--\",color=\"grey\")\n",
    "plt.plot(fpr,tpr, linewidth=2,color=\"deeppink\",label=\"GBDT\")\n",
    "#plt.plot(1 - aucRF.specificities.values,aucRF.sensitivities.values,\n",
    "#         linewidth=2,color=\"dodgerblue\",label=\"Random Forest\")\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"FPR\",fontsize = 16)\n",
    "plt.ylabel(\"TPR\",fontsize = 16)\n",
    "plt.legend(fontsize=16,loc=4)\n",
    "plt.title(\"SDQ score\",fontsize=16)\n",
    "plt.grid()\n",
    "#plt.savefig('plots/AUC-curves-SDQ-fase4-01.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faba05ec-b65d-4974-96c9-2bf2e32a48ad",
   "metadata": {},
   "source": [
    "## SHAP analysis\n",
    "\n",
    "We compute Shapley values using the SHAP Python package. The trained model object can be directly passed to the SHAP TreeExplainer. The TreeExplainer class can be called directly to compute SHAP values for a given dataset. The resulting SHAP values are hold by a so-called Explanation object which can be passed to plotting functions. Below we show the summary (beeswarm) plot, and a SHAP dependence scatter plot. \n",
    "\n",
    "In the current version of SHAP the argument 'group_remaining_features' cannot be toggled off, so that the sum of all remaining features is shown as a single feature at the bottom of the plot, which widens the horizontal scale. Therefore we use the summary plot function, which does not show this by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbdd2e0-07e2-4fb2-b8f4-97651e0b1ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "# create a summary plot\n",
    "shap.summary_plot(shap_values, max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82023a-f8ea-45ac-ac8c-f598b290a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,\"TotaalSDQkind_f4\"], color=shap_values[:,\"geslacht.x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f91966-6e55-4751-a2be-c4930f5bb34f",
   "metadata": {},
   "source": [
    "# Interaction effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b76bc2-be37-42e3-9bd6-18c468de1a10",
   "metadata": {},
   "source": [
    "The plot function shap.plots.scatter() uses the built-in function shap.utils.approximate_interactions() to approximate interaction effects.\n",
    "The shap_interaction_values() method from the shap.TreeExplainer class produces more reliable estimates. We use it to select features with the strongest interaction effect, and use these for visualization in the dependence scatter plots.\n",
    "\n",
    "The shap_interaction_values() method computes for each data point a $p\\times p$ matrix, stored in a 3-dimensional array. We take a slice from this 3-dimensional matrix at the feature index of choice, for example 'TotaalSDQkind_f4'. For this feature we search the feature which has the highest sum of (absolute) interaction values over all data points. This will return the selected feature itself because the interaction value with itself is simply the SHAP value for that feature and will have the highest value. We therefore take the second highest value.\n",
    "\n",
    "The strongest interacting variable for 'TotaalSDQkind_f4' is a variable for the estimation of enviromental air pollution due to NO$_2$ during pregnancy (no2_preg). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98f61e0-36bc-4bbb-b3c5-3419072aa880",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_interaction_values = explainer.shap_interaction_values(X_train)\n",
    "\n",
    "feature_idx = np.where(X.columns=='TotaalSDQkind_f4')[0][0]\n",
    "\n",
    "print(pd.Series(X.columns[np.argsort(np.sum(np.abs(shap_interaction_values[:,feature_idx,:]),axis=0))[-20:]],\n",
    "               index=np.arange(20,0,-1)).iloc[::-1])\n",
    "\n",
    "interaction_feat_idx = X.columns[np.argsort(np.sum(np.abs(shap_interaction_values[:,feature_idx,:]),axis=0))[-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68dd17c-6f72-4039-8c86-400f98c165b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,\"TotaalSDQkind_f4\"], color=shap_values[:,interaction_feat_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a8721-4e08-4fab-874d-e88c70c817d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
